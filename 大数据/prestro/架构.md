## 介绍

presto 设计的目的是为了通过分布式查询有效的查询大批量的数据，例如，查询TB或者PB级别的数据，是查询 HDFS、hive的一个可选项，但同时不局限于 HDFS, presto 适用于 OLAP 的场景。presto 并不能用来替代 mysql/pg/oracle，presto 设计的目的也不是用来处理 OLTP 场景。

## 架构图

<div align="center"> 
    <img src="../../zzzimg/presto/presto架构.png" width="50%">
</div>

## 节点角色

**coordinator**

负责解析语句、执行计划、管理 worker 节点，是 presto 的大脑；创建包含一系列 stages 查询的逻辑模型，这个模型将会被转换为一系列连接的任务运行在 presto worker 集群上； coordinators 使用 rest api 与 worker 节点通信；

**worker**

负责执行任务、处理数据，worker 节点从 connectors 拉取数据并相互交换中间数据，coordinator 负责从 worker 节点获取最终结果返回给客户端；当Presto工作进程启动时，它会在协调器中向发现服务器通告自己，从而使Presto协调器可以使用它执行任务。节点之间通过 rest api 进行通信。



**Discovery Service**

presto 使用服务发现来查找集群中所有的节点，每个注册到 Discovery Service 的节点周期性发送心跳信号，这可以使 coordinator 获取最新的可用 worker 节点列表，worker 发送心跳失败，Discovery Service 会触发失败检测，worker 将不会被分配任务。Discovery Service 是内置在 coordinator 节点中。

查询执行模型、查询计划、基于成本的优化


## 基于Connector 的架构

只要已有数据在使用 presto 的数据类型时，也可以以表、行、列的形式表达，connector 就可以创建，查询引擎也可以使用这些数据进行查询处理。

Presto 提供了 SPI 来实现一个 connector，通过在 connector 中实现 SPI，Presto 可以使用内部标准操作在任何数据上连接数据源和实施操作。每个 connector 都需要实现这个 API的三个部分：

- Operations to fetch table/view/schema metadata
- Operations to produce logical units of data partitioning, so that Presto can parallelize reads and writes
- Data sources and sinks that convert the source data to/from the in-memory format expected by the query engine

<div align="center"> 
    <img src="../../zzzimg/presto/presto connector.jpg" width="70%">
</div>


## Query Execution Model

When a SQLstatement is submitted to the coordinator, it is received in textual format. The coordinator
takes that text and parses and analyzes it. It then creates a plan for execution by
using an internal data structure in Presto called the query plan. This flow is displayed
The query plan broadly represents the needed steps to process the data
and return the results per the SQL statement.

<div align="center"> 
    <img src="../../zzzimg/presto/presto sql.jpg" width="50%">
</div>


the query plan generation uses the metadata SPI and the
data statistics SPI to create the query plan. So the coordinator uses the SPI to gather
information about tables and other metadata connecting to the data source directly.

<div align="center"> 
    <img src="../../zzzimg/presto/query plan.jpg" width="50%">
</div>

The coordinator uses the metadata SPI to get information about tables, columns, and
types. These are used to validate that the query is semantically valid, and to perform
type checking of expressions in the original query and security checks.

The statistics SPI is used to obtain information about row counts and table sizes to
perform cost-based query optimizations during planning.

The data location SPI is then facilitated in the creation of the distributed query plan.It is used to generate logical splits of the table contents. Splits are the smallest unit ofwork assignment and parallelism.

The distributed query plan is an extension of the simple query plan consisting of one
or more stages. The simple query plan is split into plan fragments. A stage is the runtime incarnation of a plan fragment, and it encompasses all the tasks of the work
described by the stage’s plan fragment.

The coordinator breaks up the plan to allow processing on clusters facilitating workers
in parallel to speed up the overall query. Having more than one stage results in the
creation of a dependency tree of stages. The number of stages depends on the complexity
of the query. For example, queried tables, returned columns, JOIN statements,
WHERE conditions, GROUP BY operations, and other SQL statements all impact the number of stages created.

<div align="center"> 
    <img src="../../zzzimg/presto/query plan transform.jpg" width="50%">
</div>

The distributed query plan defines the stages and the way the query is to execute on a
Presto cluster. It’s used by the coordinator to further plan and schedule tasks across
the workers. A stage consists of one or more tasks. Typically, many tasks are involved,
and each task processes a piece of the data.
The coordinator assigns the tasks from a stage out to the workers in the cluster, as
displayed in Figure 4-9.

<div align="center"> 
    <img src="../../zzzimg/presto/stage.jpg" width="50%">
</div>

The unit of data that a task processes is called a split. A split is a descriptor for a segment
of the underlying data that can be retrieved and processed by a worker. It is the
unit of parallelism and work assignment. The specific operations on the data performed
by the connector depend on the underlying data source.
For example, the Hive connector describes splits in the form of a path to a file with
offset and length that indicate which part of the file needs to be processed.
Tasks at the source stage produce data in the form of pages, which are a collection of
rows in columnar format. These pages flow to other intermediate downstream stages.
Pages are transferred between stages by exchange operators, which read the data from
tasks within an upstream stage.
The source tasks use the data source SPI to fetch data from the underlying data source
with the help of a connector. This data is presented to Presto and flows through the
engine in the form of pages. Operators process and produce pages according to their
semantics. For example, filters drop rows, projections produce pages with new
derived columns, and so on. The sequence of operators within a task is called a pipeline.
The last operator of a pipeline typically places its output pages in the task’s output
buffer. Exchange operators in downstream tasks consume the pages from an
upstream task’s output buffer. All these operations occur in parallel on different
workers, as seen in Figure 4-10.

<div align="center"> 
    <img src="../../zzzimg/presto/data spilt.jpg" width="50%">
</div>

So a task is the runtime incarnation of a plan fragment when assigned to a worker.
After a task is created, it instantiates a driver for each split. Each driver is an instantiation
of a pipeline of operators and performs the processing of the data in the split. A
task may use one or more drivers, depending on the Presto configuration and environment,
as shown in Figure 4-11. Once all drivers are finished, and the data is
passed to the next split, the drivers and the task are finished with their work and are
destroyed.

<div align="center"> 
    <img src="../../zzzimg/presto/task spilt.jpg" width="50%">
</div>

An operator processes input data to produce output data for a downstream operator.
Example operators are table scans, filters, joins, and aggregations. A series of these
operators form an operator pipeline. For example, you may have a pipeline that first
scans and reads the data, and then filters on the data, and finally does a partial aggregation
on the data.
To process a query, the coordinator creates the list of splits with the metadata from
the connector. Using the list of splits, the coordinator starts scheduling tasks on the
workers to gather the data in the splits. During query execution, the coordinator
tracks all splits available for processing and the locations where tasks are running on
workers and processing splits. As tasks finish processing and are producing more
splits for downstream processing, the coordinator continues to schedule tasks until
no splits remain for processing.
Once all splits are processed on the workers, all data is available, and the coordinator
can make the result available to the client.


## Query Planning

### initial plan

Unlike an imperative program, the user does not specify how to
process the data to get the result. This part is left to the query planner and optimizer
to determine the sequence of steps to process the data for the desired result.
This sequence of steps is often referred to as the query plan. Theoretically, an exponential
number of query plans could yield the same query result. The performance of the plans varies dramatically, and this is where the Presto planner and optimizer try
to determine the optimal plan. Plans that always produce the same results are called
equivalent plans.

The initial plan serves as a bridge between two worlds: the world of SQL
language and its semantic rules, and the world of query optimizations. The role of
query optimization is to transform and evolve the initial plan into an equivalent plan
that can be executed as fast as possible, at least in a reasonable amount of time, givenfinite resources of the Presto cluster.


## Optimization Rules

### Predicate Pushdown

Its role is to move the filtering condition as close to the source of the data
as possible. As a result, data reduction happens as early as possible during query execution.

### Cross Join Elimination

cross join(笛卡尔积)，没有 join 条件的 join 操作。Cross join elimination reorders the tables being joined to minimize the number of cross joins, ideally reducing it to zero.

### TOP N

During query execution, TopN keeps the desired number of rows in a heap data structure, updating the heap while reading input data in a streaming fashion.

## Cost-Based Optimizer

### The Cost Concept

Without cost-based decisions, the query planner rules optimize the initial plan for
this query to produce a plan, as shown in Example 4-9. This plan is determined solely
by the lexical structure of the SQL query. The optimizer used only the syntactic information;
hence it is sometimes called the syntactic optimizer. The name is meant to be
humorous, highlighting the simplicity of the optimizations. Since the query plan is
based only on the query, you can hand-tune or optimize the query by adjusting the
syntactic order of the tables in the query.

The fact that a simple change of ordering conditions affects the query plan, and
therefore the performance of the query, is cumbersome for the SQL analyst.

The cost-based optimizer ensures that the two variants of the query produce the same
optimal query plan for processing by Presto’s execution engine.

CPU time, memory requirements, and network bandwidth usage are the three
dimensions that contribute to query execution time, both in single-query and concurrent
workloads. These dimensions constitute the cost in Presto.

### Cost of the Join

When joining two tables over the equality condition (=), Presto implements an extended
version of the algorithm known as a hash join. One of the joined tables is called
the build side. This table is used to build a lookup hash table with the join condition
columns as the key. Another joined table is called the probe side. Once the lookup
hash table is ready, rows from the probe side are processed, and the hash table is used
to find matching build-side rows in constant time. By default, Presto uses three-level
hashing in order to parallelize processing as much as possible:
1. Both joined tables are distributed across the worker nodes, based on the hash
values of the join condition columns. Rows that should be matched have
the same values on join condition columns, so they are assigned to the same
node. This reduces the size of the problem by the number of nodes being used at
this stage. This node-level data assignment is the first level of hashing.
2. At a node level, the build side is further scattered across build-side worker
threads, again using a hash function. Building a hash table is a CPU-intensive
process, and using multiple threads to do the job greatly improves throughput.
3. Each worker thread ultimately produces one partition of the final lookup hash
table. Each partition is a hash table itself. The partitions are combined into a twolevel

lookup hash table so that we avoid scattering the probe side across multiple
threads as well. The probe side is still processed in multiple threads, but the
threads get their work assigned in batches, which is faster than partitioning the
data by using a hash function.
As you can see, the build side is kept in memory to facilitate fast, in-memory data
processing. Of course, a memory footprint is also associated, proportional to the size
of the build side. This means that the build side must fit into the memory available on
the node. This also means that less memory is available to other operations and to
other queries. This is the memory cost associated with the join. There is also the network
cost. In the algorithm described previously, both joined tables are transferred
over the network to facilitate node-level data assignment.

The cost-based optimizer can select which table should be the build table, controlling
the memory cost of the join. Under certain conditions, the optimizer can also avoid
sending one of the tables over the network, thus reducing network bandwidth usage
(reducing the network cost). To do its job, the cost-based optimizer needs to know
the size of the joined tables, which is provided as the table statistics.

### Table Statistics

Each table is provided by a connector. Besides table schema information and
access to actual data, the connector can provide table and column statistics.

With an estimation of the number of rows in the joined tables and, optionally, average
data size for columns, the cost-based optimizer already has sufficient knowledge
to determine the optimal ordering of the tables in our example query.

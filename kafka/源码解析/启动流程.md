## main 入口 kafka/Kafka.scala

```scala
// 检查参数，并从参数中获取配置
val serverProps = getPropsFromArgs(args)

// 检查配置、启动 kafkaMetricReporters、创建/启动/关闭 kafka server
val kafkaServerStartable = KafkaServerStartable.fromProps(serverProps)

// register optional signal handler that logs a message when the process is terminated
new LoggingSignalHandler().register()

// start/shutdown kafka server
kafkaServerStartable.startup()
kafkaServerStartable.awaitShutdown()
```

## KafkaServer.scala ##startup()
```scala

// 启动 zookeeper
initZkClient(time)

/* 获取或创建 cluster_id */
_clusterId = getOrGenerateClusterId(zkClient)

/* 加载 broker 元数据 */
val (preloadedBrokerMetadataCheckpoint, initialOfflineDirs) = getBrokerMetadataAndOfflineDirs

/* 生成 brokerId */
config.brokerId = getOrGenerateBrokerId(preloadedBrokerMetadataCheckpoint)

// 从 zookeeper 动态初始化 broker 配置，启动后，任何配置更新都会被应用.
config.dynamicConfig.initialize(zkClient)

/* 启动 kafka broker 调度模块 */
kafkaScheduler = new KafkaScheduler(config.backgroundThreads)

// 创建配置 metric
reporters.add(new JmxReporter(jmxPrefix))

/* 启动数据管理 */
logManager = LogManager(config, initialOfflineDirs, zkClient, brokerState, kafkaScheduler, time, brokerTopicStats, logDirFailureChannel)

// 为所有紧急停堆机制(SCRAM mechanisms)启用委派令牌缓存以简化动态更新
// 如果动态启用新的紧急停堆机制，这将使缓存保持最新
tokenCache = new DelegationTokenCache(ScramMechanism.mechanismNames)
credentialProvider = new CredentialProvider(ScramMechanism.mechanismNames, tokenCache)

// Create and start the socket server acceptor threads so that the bound port is known.
// Delay starting processors until the end of the initialization sequence to ensure
// that credentials have been loaded before processing authentications.
socketServer = new SocketServer(config, metrics, time, credentialProvider)
socketServer.startup(startupProcessors = false)

// 副本管理
replicaManager = createReplicaManager(isShuttingDown)

// 启动 controller
 kafkaController = new KafkaController(config, zkClient, time, metrics, brokerInfo, brokerEpoch, tokenManager, threadNamePrefix)

 // 启动 group coordinator
 groupCoordinator = GroupCoordinator(config, zkClient, replicaManager, Time.SYSTEM, metrics)

// 启动 transaction coordinator
 transactionCoordinator = TransactionCoordinator(config, replicaManager, new KafkaScheduler(threads = 1, threadNamePrefix = "transaction-log-manager-"), zkClient, metrics, metadataCache, Time.SYSTEM)

 /* 启动 processing requests */
dataPlaneRequestProcessor = new KafkaApis(socketServer.dataPlaneRequestChannel, replicaManager, adminManager, groupCoordinator, transactionCoordinator, kafkaController, zkClient, config.brokerId, config, metadataCache, metrics, authorizer, quotaManagers,fetchManager, brokerTopicStats, clusterId, time, tokenManager)

dataPlaneRequestHandlerPool = new KafkaRequestHandlerPool(config.brokerId, socketServer.dataPlaneRequestChannel, dataPlaneRequestProcessor, time,config.numIoThreads, s"${SocketServer.DataPlaneMetricPrefix}RequestHandlerAvgIdlePercent", SocketServer.DataPlaneThreadPrefix)

```




